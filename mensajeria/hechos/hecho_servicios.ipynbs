{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498e6b90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:14:48.899388Z",
     "iopub.status.busy": "2025-06-30T19:14:48.899056Z",
     "iopub.status.idle": "2025-06-30T19:15:02.716116Z",
     "shell.execute_reply": "2025-06-30T19:15:02.715253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\ervin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.0.41)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\ervin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy) (3.2.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\ervin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy) (4.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\users\\ervin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.9.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in c:\\users\\ervin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.9.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\ervin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\ervin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.3.1)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\ervin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ervin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ervin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ervin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\ervin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ervin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ervin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ervin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ervin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Instalación de librerías requeridas\n",
    "%pip install sqlalchemy\n",
    "%pip install psycopg2\n",
    "%pip install psycopg2-binary\n",
    "%pip install scikit-learn\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad2e711d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:15:02.719366Z",
     "iopub.status.busy": "2025-06-30T19:15:02.718985Z",
     "iopub.status.idle": "2025-06-30T19:15:03.508672Z",
     "shell.execute_reply": "2025-06-30T19:15:03.507690Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53ca9ba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:15:03.512180Z",
     "iopub.status.busy": "2025-06-30T19:15:03.511698Z",
     "iopub.status.idle": "2025-06-30T19:15:03.522515Z",
     "shell.execute_reply": "2025-06-30T19:15:03.521601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'driver': 'postgresql+psycopg2',\n",
       " 'host': 'localhost',\n",
       " 'port': 5432,\n",
       " 'user': 'postgres',\n",
       " 'password': 'Ec94',\n",
       " 'db': 'proyectob'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../../configBD/config.yml', 'r') as f:\n",
    "    cfg        = yaml.safe_load(f)\n",
    "    cfg_etl    = cfg['bodega']\n",
    "    cfg_bd     = cfg['mensajeria']\n",
    "cfg_etl       # verificación rápida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feff970a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:15:03.526066Z",
     "iopub.status.busy": "2025-06-30T19:15:03.525367Z",
     "iopub.status.idle": "2025-06-30T19:15:03.536546Z",
     "shell.execute_reply": "2025-06-30T19:15:03.535675Z"
    }
   },
   "outputs": [],
   "source": [
    "url_bd  = f\"{cfg_bd['driver']}://{cfg_bd['user']}:{cfg_bd['password']}@{cfg_bd['host']}:{cfg_bd['port']}/{cfg_bd['db']}\"\n",
    "url_etl = f\"{cfg_etl['driver']}://{cfg_etl['user']}:{cfg_etl['password']}@{cfg_etl['host']}:{cfg_etl['port']}/{cfg_etl['db']}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "798de0a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:15:03.539947Z",
     "iopub.status.busy": "2025-06-30T19:15:03.539127Z",
     "iopub.status.idle": "2025-06-30T19:15:03.611902Z",
     "shell.execute_reply": "2025-06-30T19:15:03.610929Z"
    }
   },
   "outputs": [],
   "source": [
    "cliente_bd  = create_engine(url_bd)     # base operativa\n",
    "cliente_etl = create_engine(url_etl)    # Data Warehouse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ffd81c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:15:03.615891Z",
     "iopub.status.busy": "2025-06-30T19:15:03.615397Z",
     "iopub.status.idle": "2025-06-30T19:15:04.313475Z",
     "shell.execute_reply": "2025-06-30T19:15:04.312600Z"
    }
   },
   "outputs": [],
   "source": [
    "dim_cliente   = pd.read_sql_table('dim_cliente',   url_etl)\n",
    "dim_mensajero = pd.read_sql_table('dim_mensajero', url_etl)\n",
    "dim_sede      = pd.read_sql_table('dim_sede',      url_etl)\n",
    "dim_tiempo    = pd.read_sql_table('dim_tiempo',    url_etl)\n",
    "\n",
    "# normaliza dim_tiempo → genera columna date\n",
    "dim_tiempo = dim_tiempo.rename(columns={'Año':'year','Mes':'month','Dia':'day'})\n",
    "dim_tiempo['date'] = pd.to_datetime(dim_tiempo[['year','month','day']]).dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f187b72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:15:04.317319Z",
     "iopub.status.busy": "2025-06-30T19:15:04.316711Z",
     "iopub.status.idle": "2025-06-30T19:15:10.831634Z",
     "shell.execute_reply": "2025-06-30T19:15:10.830767Z"
    }
   },
   "outputs": [],
   "source": [
    "servicios      = pd.read_sql_table('mensajeria_servicio',        url_bd)\n",
    "origenes       = pd.read_sql_table('mensajeria_origenservicio',  url_bd)\n",
    "destinos       = pd.read_sql_table('mensajeria_destinoservicio', url_bd)\n",
    "estados_srv    = pd.read_sql_table('mensajeria_estadosservicio', url_bd)\n",
    "cat_estado     = pd.read_sql_table('mensajeria_estado',          url_bd)\n",
    "cat_tipo_srv   = pd.read_sql_table('mensajeria_tiposervicio',    url_bd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28d24f5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:15:10.835997Z",
     "iopub.status.busy": "2025-06-30T19:15:10.835679Z",
     "iopub.status.idle": "2025-06-30T19:15:54.972927Z",
     "shell.execute_reply": "2025-06-30T19:15:54.971752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'descripcion', 'nombre_solicitante', 'fecha_solicitud', 'hora_solicitud', 'fecha_deseada', 'hora_deseada', 'nombre_recibe', 'telefono_recibe', 'descripcion_pago', 'ida_y_regreso', 'activo', 'novedades', 'cliente_id', 'destino_id', 'mensajero_id', 'origen_id', 'tipo_pago_id', 'tipo_servicio_id', 'tipo_vehiculo_id', 'usuario_id', 'prioridad', 'ciudad_destino_id', 'ciudad_origen_id', 'hora_visto_por_mensajero', 'visto_por_mensajero', 'descripcion_multiples_origenes', 'mensajero2_id', 'mensajero3_id', 'multiples_origenes', 'asignar_mensajero', 'es_prueba', 'descripcion_cancelado', 'FechaSolicitud', 'TiempoKey']\n",
      "['id', 'descripcion', 'nombre_solicitante', 'fecha_solicitud', 'hora_solicitud', 'fecha_deseada', 'hora_deseada', 'nombre_recibe', 'telefono_recibe', 'descripcion_pago', 'ida_y_regreso', 'activo', 'novedades', 'cliente_id', 'destino_id', 'mensajero_id', 'origen_id', 'tipo_pago_id', 'tipo_servicio_id', 'tipo_vehiculo_id', 'usuario_id', 'prioridad', 'ciudad_destino_id', 'ciudad_origen_id', 'hora_visto_por_mensajero', 'visto_por_mensajero', 'descripcion_multiples_origenes', 'mensajero2_id', 'mensajero3_id', 'multiples_origenes', 'asignar_mensajero', 'es_prueba', 'descripcion_cancelado', 'FechaSolicitud', 'TiempoKey', 'ClienteKey']\n",
      "['id', 'descripcion', 'nombre_solicitante', 'fecha_solicitud', 'hora_solicitud', 'fecha_deseada', 'hora_deseada', 'nombre_recibe', 'telefono_recibe', 'descripcion_pago', 'ida_y_regreso', 'activo', 'novedades', 'cliente_id', 'destino_id', 'mensajero_id', 'origen_id', 'tipo_pago_id', 'tipo_servicio_id', 'tipo_vehiculo_id', 'usuario_id', 'prioridad', 'ciudad_destino_id', 'ciudad_origen_id', 'hora_visto_por_mensajero', 'visto_por_mensajero', 'descripcion_multiples_origenes', 'mensajero2_id', 'mensajero3_id', 'multiples_origenes', 'asignar_mensajero', 'es_prueba', 'descripcion_cancelado', 'FechaSolicitud', 'TiempoKey', 'ClienteKey', 'MensajeroKey']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ervin\\AppData\\Local\\Temp\\ipykernel_7076\\2763355731.py:171: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  fact_serv['Tiempo_Mensajero_Asignado'] = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'descripcion', 'nombre_solicitante', 'nombre_recibe', 'telefono_recibe', 'descripcion_pago', 'ida_y_regreso', 'activo', 'novedades', 'destino_id', 'mensajero_id', 'origen_id', 'tipo_pago_id', 'tipo_servicio_id', 'tipo_vehiculo_id', 'usuario_id', 'prioridad', 'visto_por_mensajero', 'descripcion_multiples_origenes', 'mensajero2_id', 'mensajero3_id', 'multiples_origenes', 'asignar_mensajero', 'es_prueba', 'descripcion_cancelado', 'FechaSolicitud', 'TiempoKey', 'ClienteKey', 'MensajeroKey', 'SedeOrigenKey', 'SedeDestinoKey', 'TipoServicio', 'EstadoServicio', 'timestamp', 'EsFinal', 'Tiempo_Inicio', 'Tiempo_Mensajero_Asignado', 'Tiempo_Recogido_Origen', 'Tiempo_Entregado_Destino', 'Tiempo_Cerrado']\n"
     ]
    }
   ],
   "source": [
    "# ----- 0) copia base -----\n",
    "fact_serv = servicios.copy()\n",
    "\n",
    "# ----- 1) TiempoKey (fecha_solicitud) -----\n",
    "fact_serv['FechaSolicitud']   = pd.to_datetime(fact_serv['fecha_solicitud']).dt.date\n",
    "dim_tiempo_subset = dim_tiempo[['tiempo_key','date']].rename(columns={'tiempo_key':'TiempoKey'})\n",
    "fact_serv = fact_serv.merge(dim_tiempo_subset,\n",
    "                            left_on='FechaSolicitud',\n",
    "                            right_on='date', how='left') \\\n",
    "                     .drop(columns=['date'])\n",
    "print(fact_serv.columns.tolist())\n",
    "\n",
    "\n",
    "# ----- 2) FK Cliente -----\n",
    "fact_serv = fact_serv.merge(dim_cliente[['ClienteKey','cliente_id']],\n",
    "                            on='cliente_id', how='left')\n",
    "print(fact_serv.columns.tolist())\n",
    "\n",
    "\n",
    "# ----- 3) FK Mensajero (titular) -----\n",
    "fact_serv = fact_serv.merge(dim_mensajero[['MensajeroKey','user_id']],\n",
    "                            left_on='mensajero_id', right_on='user_id',\n",
    "                            how='left').drop(columns=['user_id'])\n",
    "print(fact_serv.columns.tolist())\n",
    "\n",
    "\n",
    "# ----- 4) FK Sede Origen y Destino -----\n",
    "# 4a) unir origen\n",
    "fact_serv = (\n",
    "    fact_serv\n",
    "    .merge(\n",
    "        origenes[['id','cliente_id','ciudad_id']],\n",
    "        left_on='origen_id', right_on='id',\n",
    "        how='left',\n",
    "        suffixes=('','_ori')      # id→id_ori\n",
    "    )\n",
    "    .rename(columns={\n",
    "        'ciudad_id':      'ciudad_ori',\n",
    "        'cliente_id_ori': 'cliente_ori'\n",
    "    })\n",
    "    .drop(columns=['id_ori'])    # <— borramos sólo id_ori, NO id\n",
    ")\n",
    "\n",
    "# 4b) unir destino\n",
    "fact_serv = (\n",
    "    fact_serv\n",
    "    .merge(\n",
    "        destinos[['id','cliente_id','ciudad_id']],\n",
    "        left_on='destino_id', right_on='id',\n",
    "        how='left',\n",
    "        suffixes=('','_des')      # id→id_des\n",
    "    )\n",
    "    .rename(columns={\n",
    "        'ciudad_id':      'ciudad_des',\n",
    "        'cliente_id_des': 'cliente_des'\n",
    "    })\n",
    "    .drop(columns=['id_des'])    # <— borramos sólo id_des\n",
    ")\n",
    "\n",
    "\n",
    "# 4c  lookup en dim_sede\n",
    "# fact_serv = fact_serv.merge(dim_sede[['SedeKey','ciudad_id','cliente_id']],\n",
    "#                             left_on=['ciudad_ori','cliente_ori'],\n",
    "#                             right_on=['ciudad_id','cliente_id'],\n",
    "#                             how='left').rename(columns={'SedeKey':'SedeOrigenKey'}) \\\n",
    "#                      .drop(columns=['ciudad_id','cliente_id'])\n",
    "# 4c) lookup en dim_sede para SedeOrigenKey\n",
    "fact_serv = (\n",
    "    fact_serv\n",
    "    .merge(\n",
    "        dim_sede[['SedeKey','ciudad_id','cliente_id']],\n",
    "        left_on=['ciudad_ori','cliente_ori'],\n",
    "        right_on=['ciudad_id','cliente_id'],\n",
    "        how='left',\n",
    "        suffixes=('','_dim')           # sufijo solo en cliente_id de dim_sede\n",
    "    )\n",
    "    .rename(columns={'SedeKey':'SedeOrigenKey'})\n",
    "    .drop(columns=['ciudad_id','cliente_id_dim'])  # elimina la ciudad_id traída y el cliente_id_dim\n",
    ")\n",
    "\n",
    "# 4d) lookup en dim_sede para SedeDestinoKey (idéntico, cambiando sólo nombres)\n",
    "fact_serv = (\n",
    "    fact_serv\n",
    "    .merge(\n",
    "        dim_sede[['SedeKey','ciudad_id','cliente_id']],\n",
    "        left_on=['ciudad_des','cliente_des'],\n",
    "        right_on=['ciudad_id','cliente_id'],\n",
    "        how='left',\n",
    "        suffixes=('','_dim')\n",
    "    )\n",
    "    .rename(columns={'SedeKey':'SedeDestinoKey'})\n",
    "    .drop(columns=['ciudad_id','cliente_id_dim'])\n",
    ")\n",
    "\n",
    "# ----- 5) TipoServicio -----\n",
    "fact_serv = (\n",
    "    fact_serv\n",
    "    .merge(\n",
    "        cat_tipo_srv[['id','nombre']],\n",
    "        left_on='tipo_servicio_id',\n",
    "        right_on='id',\n",
    "        how='left',\n",
    "        suffixes=('','_tipo')\n",
    "    )\n",
    "    .rename(columns={'nombre':'TipoServicio'})\n",
    "    .drop(columns=['id_tipo'])\n",
    ")\n",
    "\n",
    "# ----- 6) EstadoServicio (último estado registrado) -----\n",
    "# 6a) fusionar nombre del estado\n",
    "# 6a) fusionar nombre del estado\n",
    "estados_srv = (\n",
    "    estados_srv\n",
    "    .merge(\n",
    "        cat_estado[['id','nombre']],\n",
    "        left_on='estado_id',\n",
    "        right_on='id',\n",
    "        how='left',\n",
    "        suffixes=('','_cat')\n",
    "    )\n",
    "    .rename(columns={'nombre':'EstadoNom'})\n",
    "    .drop(columns=['id_cat'])\n",
    ")\n",
    "\n",
    "# ———————> dedupe columns <———————\n",
    "estados_srv = estados_srv.loc[:, ~estados_srv.columns.duplicated()]\n",
    "\n",
    "\n",
    "# 6b) timestamp con microsegundos\n",
    "estados_srv['timestamp'] = pd.to_datetime(\n",
    "    estados_srv['fecha'].astype(str) + ' ' + estados_srv['hora'].astype(str),\n",
    "    format='%Y-%m-%d %H:%M:%S.%f',\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# 6c) extraer último estado\n",
    "ult_estado = (\n",
    "    estados_srv\n",
    "    .sort_values('timestamp')\n",
    "    .groupby('servicio_id', as_index=False)\n",
    "    .tail(1)[['servicio_id','EstadoNom','timestamp']]\n",
    ")\n",
    "\n",
    "# 6d) merge en fact_serv\n",
    "fact_serv = (\n",
    "    fact_serv\n",
    "    .merge(ult_estado,\n",
    "           left_on='id', right_on='servicio_id',\n",
    "           how='left')\n",
    "    .rename(columns={'EstadoNom':'EstadoServicio'})\n",
    "    .drop(columns=['servicio_id'])\n",
    ")\n",
    "\n",
    "# ————————————— CORRECCIÓN —————————————\n",
    "# Elimina cualquier columna duplicada (por si quedaron dos 'EstadoServicio')\n",
    "fact_serv = fact_serv.loc[:, ~fact_serv.columns.duplicated()]\n",
    "\n",
    "# ----- 7) EsFinal (TRUE si el estado es uno de los finales) -----\n",
    "finales = ['ENTREGADO','CERRADO','CANCELADO']\n",
    "fact_serv['EsFinal'] = fact_serv['EstadoServicio'].isin(finales)\n",
    "\n",
    "# ----- 8) Timestamps de tracking alternativos -----\n",
    "# 8.1) Inicio = fecha_solicitud + hora_solicitud\n",
    "fact_serv['Tiempo_Inicio'] = pd.to_datetime(\n",
    "    fact_serv['fecha_solicitud'].astype(str) + ' ' +\n",
    "    fact_serv['hora_solicitud'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# 8.2) Asignado = fecha_solicitud + hora_visto_por_mensajero\n",
    "fact_serv['Tiempo_Mensajero_Asignado'] = pd.to_datetime(\n",
    "    fact_serv['fecha_solicitud'].astype(str) + ' ' +\n",
    "    fact_serv['hora_visto_por_mensajero'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# 8.3) Recogido = fecha_deseada + hora_deseada\n",
    "fact_serv['Tiempo_Recogido_Origen'] = pd.to_datetime(\n",
    "    fact_serv['fecha_deseada'].astype(str) + ' ' +\n",
    "    fact_serv['hora_deseada'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# 8.4) Entregado = Recogido + horas según prioridad\n",
    "priority_hours = {\n",
    "    'Alta: En una Hora':        1,\n",
    "    'Media: De 1 a 3 horas':    2,\n",
    "    'Media: De 1 - 3 Horas':    2,\n",
    "    'Baja: Transcurso del Dia':  8\n",
    "}\n",
    "fact_serv['Tiempo_Entregado_Destino'] = (\n",
    "    fact_serv['Tiempo_Recogido_Origen'] +\n",
    "    fact_serv['prioridad']\n",
    "             .map(priority_hours)\n",
    "             .fillna(1)\n",
    "             .apply(lambda h: pd.Timedelta(hours=h))\n",
    ")\n",
    "\n",
    "# 8.5) Cerrado = Entregado + 30 minutos\n",
    "fact_serv['Tiempo_Cerrado'] = (\n",
    "    fact_serv['Tiempo_Entregado_Destino'] +\n",
    "    pd.Timedelta(minutes=30)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _extrae_evt(df, estado_nombre, new_col):\n",
    "    tmp = df[df['EstadoNom'] == estado_nombre].copy()\n",
    "    tmp['ts'] = pd.to_datetime(\n",
    "        tmp['fecha'].astype(str) + ' ' + tmp['hora'].astype(str),\n",
    "        errors='coerce'\n",
    "    )\n",
    "    return (\n",
    "        tmp.sort_values('ts')\n",
    "           .groupby('servicio_id', as_index=False)\n",
    "           .head(1)[['servicio_id','ts']]\n",
    "           .rename(columns={'ts': new_col})\n",
    "    )\n",
    "\n",
    "# for estado, new_col in [\n",
    "#     ('RECOGIDO_ORIGEN',     'Tiempo_Recogido_Origen'),\n",
    "#     ('ENTREGADO_DESTINO',   'Tiempo_Entregado_Destino'),\n",
    "#     ('CERRADO',             'Tiempo_Cerrado')\n",
    "# ]:\n",
    "#     evt = _extrae_evt(estados_srv, estado, new_col)\n",
    "#     fact_serv = (\n",
    "#         fact_serv\n",
    "#         .merge(evt,\n",
    "#                left_on='id',\n",
    "#                right_on='servicio_id',\n",
    "#                how='left')\n",
    "#         .drop(columns=['servicio_id'])\n",
    "#     )\n",
    "\n",
    "\n",
    "# ----- 9) limpieza de columnas intermedias -----\n",
    "drop_cols = (\n",
    "    [c for c in fact_serv.columns if c.startswith(('fecha_','hora_','ciudad_','cliente_'))]\n",
    "    + ['servicio_id']\n",
    ")\n",
    "fact_serv = fact_serv.drop(columns=drop_cols, errors='ignore')\n",
    "# print(fact_serv.columns.tolist())\n",
    "\n",
    "# to_drop = [c for c in fact_serv.columns if c.endswith(('_x','_y'))]\n",
    "# fact_serv = fact_serv.drop(columns=to_drop)\n",
    "print(fact_serv.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6d7dbb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:15:54.993399Z",
     "iopub.status.busy": "2025-06-30T19:15:54.992867Z",
     "iopub.status.idle": "2025-06-30T19:16:00.156579Z",
     "shell.execute_reply": "2025-06-30T19:16:00.155655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ServicioKey  TiempoKey  ClienteKey  SedeOrigenKey  SedeDestinoKey  \\\n",
      "0              34     7152.0           7           16.0            16.0   \n",
      "1              34     7152.0           7           16.0            17.0   \n",
      "2              34     7152.0           7           16.0            19.0   \n",
      "3              34     7152.0           7           16.0            24.0   \n",
      "4              34     7152.0           7           16.0            49.0   \n",
      "...           ...        ...         ...            ...             ...   \n",
      "4995           43     7458.0           7           49.0            24.0   \n",
      "4996           43     7458.0           7           49.0            49.0   \n",
      "4997           43     7458.0           7           49.0            50.0   \n",
      "4998           43     7458.0           7           50.0            16.0   \n",
      "4999           43     7458.0           7           50.0            17.0   \n",
      "\n",
      "      MensajeroKey TipoServicio EstadoServicio  EsFinal       Tiempo_Inicio  \\\n",
      "0              NaN      Clínico       Iniciado    False 2023-10-26 09:46:03   \n",
      "1              NaN      Clínico       Iniciado    False 2023-10-26 09:46:03   \n",
      "2              NaN      Clínico       Iniciado    False 2023-10-26 09:46:03   \n",
      "3              NaN      Clínico       Iniciado    False 2023-10-26 09:46:03   \n",
      "4              NaN      Clínico       Iniciado    False 2023-10-26 09:46:03   \n",
      "...            ...          ...            ...      ...                 ...   \n",
      "4995           NaN      Clínico       Iniciado    False 2023-11-07 10:05:15   \n",
      "4996           NaN      Clínico       Iniciado    False 2023-11-07 10:05:15   \n",
      "4997           NaN      Clínico       Iniciado    False 2023-11-07 10:05:15   \n",
      "4998           NaN      Clínico       Iniciado    False 2023-11-07 10:05:15   \n",
      "4999           NaN      Clínico       Iniciado    False 2023-11-07 10:05:15   \n",
      "\n",
      "     Tiempo_Mensajero_Asignado Tiempo_Recogido_Origen  \\\n",
      "0                          NaT    2023-10-26 09:46:03   \n",
      "1                          NaT    2023-10-26 09:46:03   \n",
      "2                          NaT    2023-10-26 09:46:03   \n",
      "3                          NaT    2023-10-26 09:46:03   \n",
      "4                          NaT    2023-10-26 09:46:03   \n",
      "...                        ...                    ...   \n",
      "4995                       NaT    2023-11-07 10:05:15   \n",
      "4996                       NaT    2023-11-07 10:05:15   \n",
      "4997                       NaT    2023-11-07 10:05:15   \n",
      "4998                       NaT    2023-11-07 10:05:15   \n",
      "4999                       NaT    2023-11-07 10:05:15   \n",
      "\n",
      "     Tiempo_Entregado_Destino      Tiempo_Cerrado  \n",
      "0         2023-10-26 10:46:03 2023-10-26 11:16:03  \n",
      "1         2023-10-26 10:46:03 2023-10-26 11:16:03  \n",
      "2         2023-10-26 10:46:03 2023-10-26 11:16:03  \n",
      "3         2023-10-26 10:46:03 2023-10-26 11:16:03  \n",
      "4         2023-10-26 10:46:03 2023-10-26 11:16:03  \n",
      "...                       ...                 ...  \n",
      "4995      2023-11-07 11:05:15 2023-11-07 11:35:15  \n",
      "4996      2023-11-07 11:05:15 2023-11-07 11:35:15  \n",
      "4997      2023-11-07 11:05:15 2023-11-07 11:35:15  \n",
      "4998      2023-11-07 11:05:15 2023-11-07 11:35:15  \n",
      "4999      2023-11-07 11:05:15 2023-11-07 11:35:15  \n",
      "\n",
      "[5000 rows x 14 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0) renombra el PK para que sea ServicioKey\n",
    "fact_serv = fact_serv.rename(columns={'id':'ServicioKey'})\n",
    "\n",
    "cols_final = [\n",
    "    'ServicioKey','TiempoKey','ClienteKey','SedeOrigenKey','SedeDestinoKey',\n",
    "    'MensajeroKey','TipoServicio','EstadoServicio','EsFinal',\n",
    "    'Tiempo_Inicio','Tiempo_Mensajero_Asignado',\n",
    "    'Tiempo_Recogido_Origen','Tiempo_Entregado_Destino','Tiempo_Cerrado'\n",
    "]\n",
    "fact_serv = fact_serv[cols_final]\n",
    "\n",
    "# Subconjunto de 5 000 filas\n",
    "fact_serv_sub = fact_serv.head(5000)\n",
    "print(fact_serv_sub)\n",
    "\n",
    "# Reset de transacción y volcado\n",
    "raw = cliente_etl.raw_connection()\n",
    "raw.rollback()\n",
    "raw.close()\n",
    "\n",
    "fact_serv_sub.to_sql(\n",
    "    'fact_servicios',\n",
    "    cliente_etl,\n",
    "    if_exists='replace',\n",
    "    index=False,\n",
    "    method='multi',\n",
    "    chunksize=1000\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
